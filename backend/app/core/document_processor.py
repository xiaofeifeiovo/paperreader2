"""
æ–‡æ¡£åå°å¤„ç†æ¨¡å—
è´Ÿè´£åè°ƒæ–‡æ¡£å¤„ç†çš„å¼‚æ­¥ä»»åŠ¡

èŒè´£:
- é€‰æ‹©åˆé€‚çš„å¤„ç†å™¨ï¼ˆPDF/DOCXï¼‰
- åè°ƒå¤„ç†æµç¨‹
- é”™è¯¯å¤„ç†å’ŒçŠ¶æ€æ ‡è®°
- ç»“æœä¿å­˜
"""
import json
import logging
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)


async def process_document_background(
    doc_id: str,
    file_path: str,
    file_type: str,
    output_base_dir: str,
    converter: str = "pix2text"
) -> None:
    """
    åå°å¼‚æ­¥å¤„ç†æ–‡æ¡£

    Args:
        doc_id: æ–‡æ¡£å”¯ä¸€ ID
        file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
        file_type: æ–‡ä»¶ç±»å‹ï¼ˆpdf/docxï¼‰
        output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
        converter: PDFè½¬æ¢å™¨åç§° (pix2text/marker)

    è¿”å›:
        Noneï¼ˆç»“æœä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿï¼‰

    çŠ¶æ€ç®¡ç†:
    - æˆåŠŸ: åˆ›å»º {doc_id}.md æ–‡ä»¶
    - å¤±è´¥: åˆ›å»º {doc_id}.error æ–‡ä»¶ï¼ˆJSON æ ¼å¼ï¼‰

    é”™è¯¯æ–‡ä»¶æ ¼å¼:
    {
      "error": "é”™è¯¯ä¿¡æ¯",
      "error_type": "é”™è¯¯ç±»å‹",
      "timestamp": "2026-01-12T18:30:00",
      "traceback": "è¯¦ç»†é”™è¯¯æ ˆ..."
    }

    è®¾è®¡å†³ç­–:
    - å¼‚æ­¥å‡½æ•°ï¼ˆæ”¯æŒ FastAPI BackgroundTasksï¼‰
    - å®Œå…¨ç‹¬ç«‹çš„é”™è¯¯å¤„ç†ï¼ˆä¸ä¾èµ–å¤–éƒ¨çŠ¶æ€ï¼‰
    - æ–‡ä»¶ç³»ç»Ÿä½œä¸ºçŠ¶æ€å­˜å‚¨ï¼ˆé¿å…æ•°æ®åº“ï¼‰
    """
    from app.core.pdf_processor import PDFProcessor, ProcessingError
    import time

    md_dir = Path(output_base_dir) / "markdown"
    md_dir.mkdir(parents=True, exist_ok=True)

    start_time = time.time()
    logger.info(
        f"ğŸš€ [BG] å¼€å§‹åå°å¤„ç†: "
        f"doc_id={doc_id}, "
        f"file_type={file_type}, "
        f"converter={converter}"
    )

    # ç³»ç»Ÿèµ„æºç›‘æ§
    try:
        import psutil
        process = psutil.Process()
        logger.info(
            f"ğŸ’» [BG] ç³»ç»Ÿèµ„æº: "
            f"cpu={process.cpu_percent()}%, "
            f"memory={process.memory_info().rss / 1024 / 1024:.1f}MB, "
            f"threads={process.num_threads()}"
        )
    except ImportError:
        logger.debug("ğŸ’» [BG] psutilæœªå®‰è£…ï¼Œè·³è¿‡èµ„æºç›‘æ§")

    try:
        # æ­¥éª¤1ï¼šé€‰æ‹©å¤„ç†å™¨
        logger.info(
            f"ğŸ“„ [BG] æ­¥éª¤1: é€‰æ‹©å¤„ç†å™¨ "
            f"(file_type={file_type}, converter={converter})"
        )
        if file_type.lower() == "pdf":
            processor = PDFProcessor(converter=converter)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")

        # å¤„ç†å™¨ä¿¡æ¯
        logger.debug(
            f"ğŸ”§ [BG] å¤„ç†å™¨å®ä¾‹: {processor.__class__.__name__}, "
            f"converter={converter}, "
            f"device={processor.device}"
        )

        # æ­¥éª¤2ï¼šå¤„ç†æ–‡æ¡£
        logger.info(f"ğŸ”„ [BG] æ­¥éª¤2: å¼€å§‹å¤„ç†æ–‡æ¡£ (doc_id={doc_id})")
        process_step_start = time.time()

        markdown_content, image_filenames = processor.process(
            file_path, doc_id, output_base_dir
        )

        processing_time = time.time() - start_time
        process_step_time = time.time() - process_step_start

        logger.info(f"â±ï¸ [BG] æ–‡æ¡£å¤„ç†è€—æ—¶: {processing_time:.2f}ç§’")

        # æ€§èƒ½æŒ‡æ ‡
        throughput = len(markdown_content) / processing_time if processing_time > 0 else 0
        logger.info(
            f"ğŸ“Š [BG] æ€§èƒ½æŒ‡æ ‡: "
            f"total_time={processing_time:.2f}s, "
            f"markdown_size={len(markdown_content)} chars, "
            f"images={len(image_filenames)}, "
            f"throughput={throughput:.0f} chars/s"
        )

        # æ­¥éª¤3ï¼šä¿å­˜ Markdown æ–‡ä»¶
        logger.info(f"ğŸ’¾ [BG] æ­¥éª¤3: ä¿å­˜Markdownæ–‡ä»¶")
        save_start = time.time()

        md_path = md_dir / f"{doc_id}.md"
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown_content)

        save_time = time.time() - save_start
        logger.info(
            f"ğŸ’¾ [BG] æ–‡ä»¶ä¿å­˜æˆåŠŸ: "
            f"path='{md_path}', "
            f"size={len(markdown_content)} chars, "
            f"time={save_time:.3f}s"
        )

        logger.info(
            f"âœ… [BG] æ–‡æ¡£å¤„ç†æˆåŠŸ: "
            f"doc_id={doc_id}, "
            f"markdown_size={len(markdown_content)}, "
            f"images={len(image_filenames)}, "
            f"time={processing_time:.2f}s"
        )

        # âœ… æ·»åŠ å¤„ç†å®Œæˆæ‘˜è¦ï¼ˆç‹¬ç«‹é”™è¯¯å¤„ç†ï¼Œé¿å…æ—¥å¿—é”™è¯¯å½±å“æ ¸å¿ƒä¸šåŠ¡ï¼‰
        try:
            if image_filenames:
                # æå‰å®šä¹‰ image_dirï¼Œå¤ç”¨å˜é‡ï¼ˆDRY åŸåˆ™ï¼‰
                image_dir = Path(output_base_dir) / "images" / doc_id

                logger.info(f"ğŸ“Š [BG] å¤„ç†å®Œæˆæ‘˜è¦:")
                logger.info(f"   â”œâ”€ æ–‡æ¡£ID: {doc_id}")
                logger.info(f"   â”œâ”€ Markdownå¤§å°: {len(markdown_content)} å­—ç¬¦")
                logger.info(f"   â”œâ”€ å›¾ç‰‡æ•°é‡: {len(image_filenames)}")
                logger.info(f"   â”œâ”€ å›¾ç‰‡ç›®å½•: {image_dir}")
                logger.info(f"   â””â”€ å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")

                # åˆ—å‡ºæ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
                if image_dir.exists():
                    actual_images = list(image_dir.glob("img_*.png"))
                    logger.info(f"ğŸ–¼ï¸ [BG] å®é™…å›¾ç‰‡æ–‡ä»¶éªŒè¯: {len(actual_images)} ä¸ªæ–‡ä»¶")
                    for img_path in sorted(actual_images):
                        file_size = img_path.stat().st_size
                        logger.info(f"   â”œâ”€ {img_path.name}: {file_size} å­—èŠ‚")
        except Exception as log_error:
            # æ—¥å¿—æ‰“å°å¤±è´¥ä¸å½±å“å¤„ç†ç»“æœ
            logger.warning(f"âš ï¸ [BG] æ‘˜è¦æ‰“å°å¤±è´¥ï¼ˆä¸å½±å“ç»“æœï¼‰: {log_error}")

    except Exception as e:
        # âœ… æ”¹è¿›ï¼šæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        processing_time = time.time() - start_time
        error_path = md_dir / f"{doc_id}.error"

        # é”™è¯¯æ—¶çš„èµ„æºçŠ¶æ€
        try:
            import psutil
            memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
        except:
            memory_mb = 0

        logger.error(
            f"âŒ [BG] æ–‡æ¡£å¤„ç†å¤±è´¥: "
            f"doc_id={doc_id}, "
            f"error={str(e)}, "
            f"time={processing_time:.2f}s, "
            f"memory={memory_mb:.1f}MB",
            exc_info=True
        )

        error_info = {
            "error": str(e),
            "error_type": type(e).__name__,
            "timestamp": datetime.now().isoformat(),
            "doc_id": doc_id,
            "file_path": file_path,
            "file_type": file_type,
            "processing_time": f"{processing_time:.2f}s",
            "traceback": __import__('traceback').format_exc()
        }

        with open(error_path, "w", encoding="utf-8") as f:
            json.dump(error_info, f, ensure_ascii=False, indent=2)

        logger.debug(f"ğŸ’¾ [BG] é”™è¯¯ä¿¡æ¯å·²ä¿å­˜: {error_path}")
